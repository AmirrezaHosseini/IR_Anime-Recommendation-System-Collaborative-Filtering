{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anime Recommender (pt 2 - CLF)\n",
    "\n",
    "Welcome to part 2 of my anime recommender. Here I will use collaborative filtering through a library called Surprise. To recap from [part 1](https://github.com/Mayank-Bhatia/Anime-Recommender/blob/master/Part_1_KNN.ipynb), we have a dataset containing information on user preference data from 73,516 users on 12,294 anime, found on [myanimelist.net](https://myanimelist.net/). In an attempt to build an anime recommendation system, a Nearest Neighbors appraoch returned some interesting results in the form of anime that were fairly similar to the queried anime. However, it failed to stand up to a deeper degree of similarity that is provided on myanimelist.net in the form of user recommendations - aka recommendations made and voted on by users themselves.\n",
    "\n",
    "This is a good motivation to try a more powerful technique for building recommendation systems, that of collaborative filtering. This is a technique that recommends items to users based on the preferences other users have expressed for those items.\n",
    "\n",
    "Before we start, let's acknowledge the fast that myanimelist.net has a recommendation section for each anime where users can recommend similar anime. Here's is [Death Note's](https://myanimelist.net/anime/1535/Death_Note/userrecs). Can we build a model that generates similar anime that the viewerbase would approve of? \n",
    "\n",
    "Let's begin by importing the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'KNNBasic' from 'surprise' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msurprise\u001b[39;00m \u001b[39mimport\u001b[39;00m KNNBasic, KNNWithMeans, KNNBaseline\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msurprise\u001b[39;00m \u001b[39mimport\u001b[39;00m Dataset\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msurprise\u001b[39;00m \u001b[39mimport\u001b[39;00m GridSearch, print_perf\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'KNNBasic' from 'surprise' (unknown location)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from surprise import KNNBasic, KNNWithMeans, KNNBaseline\n",
    "from surprise import Dataset\n",
    "from surprise import GridSearch, print_perf\n",
    "from surprise import Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Collecting scikit-surprise\n",
      "  Using cached scikit-surprise-1.1.3.tar.gz (771 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: joblib>=1.0.0 in d:\\workers\\bootcamp\\bootcamp_project2\\qenv\\lib\\site-packages (from scikit-surprise) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in d:\\workers\\bootcamp\\bootcamp_project2\\qenv\\lib\\site-packages (from scikit-surprise) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in d:\\workers\\bootcamp\\bootcamp_project2\\qenv\\lib\\site-packages (from scikit-surprise) (1.10.1)\n",
      "Building wheels for collected packages: scikit-surprise\n",
      "  Building wheel for scikit-surprise (setup.py): started\n",
      "  Building wheel for scikit-surprise (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for scikit-surprise\n",
      "Failed to build scikit-surprise\n",
      "Installing collected packages: scikit-surprise\n",
      "  Running setup.py install for scikit-surprise: started\n",
      "  Running setup.py install for scikit-surprise: finished with status 'error'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py bdist_wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [76 lines of output]\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\n",
      "      creating build\\lib.win-amd64-cpython-310\n",
      "      creating build\\lib.win-amd64-cpython-310\\surprise\n",
      "      copying surprise\\accuracy.py -> build\\lib.win-amd64-cpython-310\\surprise\n",
      "      copying surprise\\builtin_datasets.py -> build\\lib.win-amd64-cpython-310\\surprise\n",
      "      copying surprise\\dataset.py -> build\\lib.win-amd64-cpython-310\\surprise\n",
      "      copying surprise\\dump.py -> build\\lib.win-amd64-cpython-310\\surprise\n",
      "      copying surprise\\reader.py -> build\\lib.win-amd64-cpython-310\\surprise\n",
      "      copying surprise\\trainset.py -> build\\lib.win-amd64-cpython-310\\surprise\n",
      "      copying surprise\\utils.py -> build\\lib.win-amd64-cpython-310\\surprise\n",
      "      copying surprise\\__init__.py -> build\\lib.win-amd64-cpython-310\\surprise\n",
      "      copying surprise\\__main__.py -> build\\lib.win-amd64-cpython-310\\surprise\n",
      "      creating build\\lib.win-amd64-cpython-310\\surprise\\model_selection\n",
      "      copying surprise\\model_selection\\search.py -> build\\lib.win-amd64-cpython-310\\surprise\\model_selection\n",
      "      copying surprise\\model_selection\\split.py -> build\\lib.win-amd64-cpython-310\\surprise\\model_selection\n",
      "      copying surprise\\model_selection\\validation.py -> build\\lib.win-amd64-cpython-310\\surprise\\model_selection\n",
      "      copying surprise\\model_selection\\__init__.py -> build\\lib.win-amd64-cpython-310\\surprise\\model_selection\n",
      "      creating build\\lib.win-amd64-cpython-310\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\algo_base.py -> build\\lib.win-amd64-cpython-310\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\baseline_only.py -> build\\lib.win-amd64-cpython-310\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\knns.py -> build\\lib.win-amd64-cpython-310\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\predictions.py -> build\\lib.win-amd64-cpython-310\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\random_pred.py -> build\\lib.win-amd64-cpython-310\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\__init__.py -> build\\lib.win-amd64-cpython-310\\surprise\\prediction_algorithms\n",
      "      running egg_info\n",
      "      writing scikit_surprise.egg-info\\PKG-INFO\n",
      "      writing dependency_links to scikit_surprise.egg-info\\dependency_links.txt\n",
      "      writing entry points to scikit_surprise.egg-info\\entry_points.txt\n",
      "      writing requirements to scikit_surprise.egg-info\\requires.txt\n",
      "      writing top-level names to scikit_surprise.egg-info\\top_level.txt\n",
      "      reading manifest file 'scikit_surprise.egg-info\\SOURCES.txt'\n",
      "      reading manifest template 'MANIFEST.in'\n",
      "      adding license file 'LICENSE.md'\n",
      "      writing manifest file 'scikit_surprise.egg-info\\SOURCES.txt'\n",
      "      d:\\Workers\\Bootcamp\\bootcamp_project2\\qenv\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'surprise.prediction_algorithms' as data is deprecated, please list it in `packages`.\n",
      "          !!\n",
      "      \n",
      "      \n",
      "          ############################\n",
      "          # Package would be ignored #\n",
      "          ############################\n",
      "          Python recognizes 'surprise.prediction_algorithms' as an importable package,\n",
      "          but it is not listed in the `packages` configuration of setuptools.\n",
      "      \n",
      "          'surprise.prediction_algorithms' has been automatically added to the distribution only\n",
      "          because it may contain data files, but this behavior is likely to change\n",
      "          in future versions of setuptools (and therefore is considered deprecated).\n",
      "      \n",
      "          Please make sure that 'surprise.prediction_algorithms' is included as a package by using\n",
      "          the `packages` configuration field or the proper discovery methods\n",
      "          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "          instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "          You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "          documentation page.\n",
      "      \n",
      "      \n",
      "      !!\n",
      "      \n",
      "        check.warn(importable)\n",
      "      copying surprise\\similarities.c -> build\\lib.win-amd64-cpython-310\\surprise\n",
      "      copying surprise\\similarities.pyx -> build\\lib.win-amd64-cpython-310\\surprise\n",
      "      copying surprise\\prediction_algorithms\\co_clustering.c -> build\\lib.win-amd64-cpython-310\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\matrix_factorization.c -> build\\lib.win-amd64-cpython-310\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\optimize_baselines.c -> build\\lib.win-amd64-cpython-310\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\slope_one.c -> build\\lib.win-amd64-cpython-310\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\co_clustering.pyx -> build\\lib.win-amd64-cpython-310\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\matrix_factorization.pyx -> build\\lib.win-amd64-cpython-310\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\optimize_baselines.pyx -> build\\lib.win-amd64-cpython-310\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\slope_one.pyx -> build\\lib.win-amd64-cpython-310\\surprise\\prediction_algorithms\n",
      "      running build_ext\n",
      "      building 'surprise.similarities' extension\n",
      "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for scikit-surprise\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Running setup.py install for scikit-surprise did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [78 lines of output]\n",
      "      running install\n",
      "      d:\\Workers\\Bootcamp\\bootcamp_project2\\qenv\\lib\\site-packages\\setuptools\\command\\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "        warnings.warn(\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\n",
      "      creating build\\lib.win-amd64-cpython-310\n",
      "      creating build\\lib.win-amd64-cpython-310\\surprise\n",
      "      copying surprise\\accuracy.py -> build\\lib.win-amd64-cpython-310\\surprise\n",
      "      copying surprise\\builtin_datasets.py -> build\\lib.win-amd64-cpython-310\\surprise\n",
      "      copying surprise\\dataset.py -> build\\lib.win-amd64-cpython-310\\surprise\n",
      "      copying surprise\\dump.py -> build\\lib.win-amd64-cpython-310\\surprise\n",
      "      copying surprise\\reader.py -> build\\lib.win-amd64-cpython-310\\surprise\n",
      "      copying surprise\\trainset.py -> build\\lib.win-amd64-cpython-310\\surprise\n",
      "      copying surprise\\utils.py -> build\\lib.win-amd64-cpython-310\\surprise\n",
      "      copying surprise\\__init__.py -> build\\lib.win-amd64-cpython-310\\surprise\n",
      "      copying surprise\\__main__.py -> build\\lib.win-amd64-cpython-310\\surprise\n",
      "      creating build\\lib.win-amd64-cpython-310\\surprise\\model_selection\n",
      "      copying surprise\\model_selection\\search.py -> build\\lib.win-amd64-cpython-310\\surprise\\model_selection\n",
      "      copying surprise\\model_selection\\split.py -> build\\lib.win-amd64-cpython-310\\surprise\\model_selection\n",
      "      copying surprise\\model_selection\\validation.py -> build\\lib.win-amd64-cpython-310\\surprise\\model_selection\n",
      "      copying surprise\\model_selection\\__init__.py -> build\\lib.win-amd64-cpython-310\\surprise\\model_selection\n",
      "      creating build\\lib.win-amd64-cpython-310\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\algo_base.py -> build\\lib.win-amd64-cpython-310\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\baseline_only.py -> build\\lib.win-amd64-cpython-310\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\knns.py -> build\\lib.win-amd64-cpython-310\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\predictions.py -> build\\lib.win-amd64-cpython-310\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\random_pred.py -> build\\lib.win-amd64-cpython-310\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\__init__.py -> build\\lib.win-amd64-cpython-310\\surprise\\prediction_algorithms\n",
      "      running egg_info\n",
      "      writing scikit_surprise.egg-info\\PKG-INFO\n",
      "      writing dependency_links to scikit_surprise.egg-info\\dependency_links.txt\n",
      "      writing entry points to scikit_surprise.egg-info\\entry_points.txt\n",
      "      writing requirements to scikit_surprise.egg-info\\requires.txt\n",
      "      writing top-level names to scikit_surprise.egg-info\\top_level.txt\n",
      "      reading manifest file 'scikit_surprise.egg-info\\SOURCES.txt'\n",
      "      reading manifest template 'MANIFEST.in'\n",
      "      adding license file 'LICENSE.md'\n",
      "      writing manifest file 'scikit_surprise.egg-info\\SOURCES.txt'\n",
      "      d:\\Workers\\Bootcamp\\bootcamp_project2\\qenv\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'surprise.prediction_algorithms' as data is deprecated, please list it in `packages`.\n",
      "          !!\n",
      "      \n",
      "      \n",
      "          ############################\n",
      "          # Package would be ignored #\n",
      "          ############################\n",
      "          Python recognizes 'surprise.prediction_algorithms' as an importable package,\n",
      "          but it is not listed in the `packages` configuration of setuptools.\n",
      "      \n",
      "          'surprise.prediction_algorithms' has been automatically added to the distribution only\n",
      "          because it may contain data files, but this behavior is likely to change\n",
      "          in future versions of setuptools (and therefore is considered deprecated).\n",
      "      \n",
      "          Please make sure that 'surprise.prediction_algorithms' is included as a package by using\n",
      "          the `packages` configuration field or the proper discovery methods\n",
      "          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "          instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "          You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "          documentation page.\n",
      "      \n",
      "      \n",
      "      !!\n",
      "      \n",
      "        check.warn(importable)\n",
      "      copying surprise\\similarities.c -> build\\lib.win-amd64-cpython-310\\surprise\n",
      "      copying surprise\\similarities.pyx -> build\\lib.win-amd64-cpython-310\\surprise\n",
      "      copying surprise\\prediction_algorithms\\co_clustering.c -> build\\lib.win-amd64-cpython-310\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\matrix_factorization.c -> build\\lib.win-amd64-cpython-310\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\optimize_baselines.c -> build\\lib.win-amd64-cpython-310\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\slope_one.c -> build\\lib.win-amd64-cpython-310\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\co_clustering.pyx -> build\\lib.win-amd64-cpython-310\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\matrix_factorization.pyx -> build\\lib.win-amd64-cpython-310\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\optimize_baselines.pyx -> build\\lib.win-amd64-cpython-310\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\slope_one.pyx -> build\\lib.win-amd64-cpython-310\\surprise\\prediction_algorithms\n",
      "      running build_ext\n",
      "      building 'surprise.similarities' extension\n",
      "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: legacy-install-failure\n",
      "\n",
      "× Encountered error while trying to install package.\n",
      "╰─> scikit-surprise\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for output from the failure.\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-surprise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_id</th>\n",
       "      <th>name</th>\n",
       "      <th>genre</th>\n",
       "      <th>type</th>\n",
       "      <th>episodes</th>\n",
       "      <th>rating</th>\n",
       "      <th>members</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32281</td>\n",
       "      <td>Kimi no Na wa.</td>\n",
       "      <td>Drama, Romance, School, Supernatural</td>\n",
       "      <td>Movie</td>\n",
       "      <td>1</td>\n",
       "      <td>9.37</td>\n",
       "      <td>200630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5114</td>\n",
       "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
       "      <td>Action, Adventure, Drama, Fantasy, Magic, Mili...</td>\n",
       "      <td>TV</td>\n",
       "      <td>64</td>\n",
       "      <td>9.26</td>\n",
       "      <td>793665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28977</td>\n",
       "      <td>Gintama°</td>\n",
       "      <td>Action, Comedy, Historical, Parody, Samurai, S...</td>\n",
       "      <td>TV</td>\n",
       "      <td>51</td>\n",
       "      <td>9.25</td>\n",
       "      <td>114262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9253</td>\n",
       "      <td>Steins;Gate</td>\n",
       "      <td>Sci-Fi, Thriller</td>\n",
       "      <td>TV</td>\n",
       "      <td>24</td>\n",
       "      <td>9.17</td>\n",
       "      <td>673572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9969</td>\n",
       "      <td>Gintama&amp;#039;</td>\n",
       "      <td>Action, Comedy, Historical, Parody, Samurai, S...</td>\n",
       "      <td>TV</td>\n",
       "      <td>51</td>\n",
       "      <td>9.16</td>\n",
       "      <td>151266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anime_id                              name  \\\n",
       "0     32281                    Kimi no Na wa.   \n",
       "1      5114  Fullmetal Alchemist: Brotherhood   \n",
       "2     28977                          Gintama°   \n",
       "3      9253                       Steins;Gate   \n",
       "4      9969                     Gintama&#039;   \n",
       "\n",
       "                                               genre   type episodes  rating  \\\n",
       "0               Drama, Romance, School, Supernatural  Movie        1    9.37   \n",
       "1  Action, Adventure, Drama, Fantasy, Magic, Mili...     TV       64    9.26   \n",
       "2  Action, Comedy, Historical, Parody, Samurai, S...     TV       51    9.25   \n",
       "3                                   Sci-Fi, Thriller     TV       24    9.17   \n",
       "4  Action, Comedy, Historical, Parody, Samurai, S...     TV       51    9.16   \n",
       "\n",
       "   members  \n",
       "0   200630  \n",
       "1   793665  \n",
       "2   114262  \n",
       "3   673572  \n",
       "4   151266  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime = pd.read_csv('anime.csv')\n",
    "anime.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "anime_id - myanimelist.net's unique id identifying an anime <br>\n",
    "name - full name of anime <br>\n",
    "genre - comma separated list of genres for this anime <br>\n",
    "type - movie, TV, OVA, etc <br>\n",
    "episodes - how many episodes in this show. (1 if movie) <br>\n",
    "rating - average rating out of 10 for this anime <br>\n",
    "members - number of community members that are in this anime's \"group\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7813732</th>\n",
       "      <td>73515</td>\n",
       "      <td>16512</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7813733</th>\n",
       "      <td>73515</td>\n",
       "      <td>17187</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7813734</th>\n",
       "      <td>73515</td>\n",
       "      <td>22145</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7813735</th>\n",
       "      <td>73516</td>\n",
       "      <td>790</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7813736</th>\n",
       "      <td>73516</td>\n",
       "      <td>8074</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  anime_id  rating\n",
       "7813732    73515     16512       7\n",
       "7813733    73515     17187       9\n",
       "7813734    73515     22145      10\n",
       "7813735    73516       790       9\n",
       "7813736    73516      8074       9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime_rating = pd.read_csv('rating.csv')\n",
    "anime_rating.tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "user_id - non identifiable randomly generated user id <br> \n",
    "anime_id - the anime that this user has rated <br>\n",
    "rating - rating out of 10 this user has assigned (-1 if the user watched it but didn't assign a rating) <br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "Much like in part 1, we deal with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "anime_id      0\n",
       "name          0\n",
       "genre        62\n",
       "type         25\n",
       "episodes      0\n",
       "rating      230\n",
       "members       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id     0\n",
       "anime_id    0\n",
       "rating      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime_rating.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, rating.csv looks to be better behaved than anime.csv. This allows us to simply follow the same process of data cleaning as in [part 1](https://github.com/Mayank-Bhatia/Anime-Recommender/blob/master/Part_1_KNN.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "anime_id    0\n",
       "name        0\n",
       "genre       0\n",
       "type        0\n",
       "episodes    0\n",
       "rating      0\n",
       "members     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime['type'] = anime['type'].fillna('None')\n",
    "anime['genre'] = anime['genre'].fillna('None')\n",
    "anime['rating'] = anime['rating'].fillna('None')\n",
    "anime.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, rating.csv contains user-preference data, so we will train our model only on this data. Then why did I bother cleaning the anime.csv data? That's because our model will retrieve information about the similar anime from anime.csv in order to present it to the user. Here is a general view:\n",
    "\n",
    "1) Give the model an anime name <br>\n",
    "2) Convert that anime to its corresponding anime_id using anime.csv <br>\n",
    "3) Locate 10 similar anime_id for this within rating.csv <br>\n",
    "4) These anime_id are now taken back anime.csv to retrieve information about the recommended anime such as genre, rating, etc <br>\n",
    "5) Finally, display a list of 10 similar anime along with some relevant information about each anime\n",
    "\n",
    "With that said, we can see that there are two small issues with the anime_rating dataset. Firstly, there are users that have watched a show without giving it a rating afterwards. The dataset turns their lack of rating for a show into a rating of -1. Let's remove instances of such anime vewings. Secondly, some users that have seen very few anime (user_id 73516 only has 2 anime on their list). Because we are seeking to build a model that will recommend 10 similar anime, I feel it's necessary to drop rows which include users with a low anime viewing count. Let's only keep user_id with 20 or more anime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, 10,  8,  6,  9,  7,  3,  5,  4,  1,  2], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime_rating.rating.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  8,  6,  9,  7,  3,  5,  4,  1,  2], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime_rating = anime_rating[anime_rating.rating > 0] # only keep ratings between 1-10\n",
    "anime_rating.rating.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>user_anime_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7813732</th>\n",
       "      <td>73515</td>\n",
       "      <td>16512</td>\n",
       "      <td>7</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7813733</th>\n",
       "      <td>73515</td>\n",
       "      <td>17187</td>\n",
       "      <td>9</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7813734</th>\n",
       "      <td>73515</td>\n",
       "      <td>22145</td>\n",
       "      <td>10</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7813735</th>\n",
       "      <td>73516</td>\n",
       "      <td>790</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7813736</th>\n",
       "      <td>73516</td>\n",
       "      <td>8074</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  anime_id  rating  user_anime_count\n",
       "7813732    73515     16512       7               179\n",
       "7813733    73515     17187       9               179\n",
       "7813734    73515     22145      10               179\n",
       "7813735    73516       790       9                 2\n",
       "7813736    73516      8074       9                 2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime_rating['user_anime_count'] = anime_rating.groupby('user_id')['user_id'].transform(np.count_nonzero)\n",
    "anime_rating.tail() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>user_anime_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7813730</th>\n",
       "      <td>73515</td>\n",
       "      <td>13659</td>\n",
       "      <td>8</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7813731</th>\n",
       "      <td>73515</td>\n",
       "      <td>14345</td>\n",
       "      <td>7</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7813732</th>\n",
       "      <td>73515</td>\n",
       "      <td>16512</td>\n",
       "      <td>7</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7813733</th>\n",
       "      <td>73515</td>\n",
       "      <td>17187</td>\n",
       "      <td>9</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7813734</th>\n",
       "      <td>73515</td>\n",
       "      <td>22145</td>\n",
       "      <td>10</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  anime_id  rating  user_anime_count\n",
       "7813730    73515     13659       8               179\n",
       "7813731    73515     14345       7               179\n",
       "7813732    73515     16512       7               179\n",
       "7813733    73515     17187       9               179\n",
       "7813734    73515     22145      10               179"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime_rating = anime_rating[anime_rating.user_anime_count > 19] # only keep users that have seen at least 20 anime\n",
    "anime_rating.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anime_rating = anime_rating.drop('user_anime_count', axis=1) # having served its purpose, we can drop the user count column"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "At this stage, the rating dataset contains users with enough anime under their belt to influence our recommender system. We are now ready to train on this data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picking hyperparameters\n",
    "\n",
    "Let's tune hyperparameters using grid search. But before that, we load the pandas dataframe rating_data into surprise via a dummy reader. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_reader = Reader(line_format='user item rating', rating_scale=(1, 10))\n",
    "rating_data = Dataset.load_from_df(anime_rating[['user_id', 'anime_id', 'rating']], dummy_reader)\n",
    "rating_data.split(n_folds=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define measures for similarity. Included in the Surprise package are:\n",
    "\n",
    "cosine - Compute the cosine similarity between all pairs of users (or items) <br>\n",
    "msd\t- Compute the Mean Squared Difference similarity between all pairs of users (or items) <br>\n",
    "pearson_baseline - Compute the (shrunk) Pearson correlation coefficient between all pairs of users (or items) using baselines for centering instead of means <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_options1 = {'name': 'pearson_baseline', 'user_based': False}\n",
    "sim_options2 = {'name': 'msd', 'user_based': False}\n",
    "sim_options3 = {'name': 'cosine', 'user_based': False}\n",
    "\n",
    "bsl_options1 = {'method': 'als', 'learning_rate': .001}\n",
    "bsl_options2 = {'method': 'sgd', 'learning_rate': .001}\n",
    "\n",
    "param_grid = {'sim_options': [sim_options1,sim_options2,sim_options3]}\n",
    "\n",
    "param_grid_bsl = {'sim_options': [sim_options1,sim_options2,sim_options3],\n",
    "                  'bsl_options': [bsl_options1,bsl_options2]}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now ready to set up our grid search using algorithms that are directly derived from a basic nearest neighbors approach. Included in the Surprise package are:\n",
    "\n",
    "KNNBasic - A basic collaborative filtering algorithm using nearest neighbors <br>\n",
    "KNNWithMeans - A basic collaborative filtering algorithm, taking into account the mean ratings of each user <br>\n",
    "KNNBaseline - A basic collaborative filtering algorithm taking into account a baseline rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_basic = GridSearch(KNNBasic, param_grid, measures=['RMSE', 'FCP'], verbose=0)\n",
    "grid_search_means = GridSearch(KNNWithMeans, param_grid, measures=['RMSE', 'FCP'], verbose=0)\n",
    "grid_search_bsl = GridSearch(KNNBaseline, param_grid_bsl, measures=['RMSE', 'FCP'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mike\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\surprise\\prediction_algorithms\\algo_base.py:231: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sim = construction_func[name](*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "grid_search_basic.evaluate(rating_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mike\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\surprise\\prediction_algorithms\\algo_base.py:231: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sim = construction_func[name](*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "grid_search_means.evaluate(rating_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using sgd...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using sgd...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using sgd...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mike\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\surprise\\prediction_algorithms\\algo_base.py:231: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sim = construction_func[name](*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using sgd...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using sgd...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using sgd...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "grid_search_bsl.evaluate(rating_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the best RMSE scores and parameters as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.18593231147\n",
      "{'sim_options': {'user_based': False, 'name': 'pearson_baseline'}}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_basic.best_score['RMSE'])\n",
    "print(grid_search_basic.best_params['RMSE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11228556969\n",
      "{'sim_options': {'user_based': False, 'name': 'pearson_baseline'}}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_means.best_score['RMSE'])\n",
    "print(grid_search_means.best_params['RMSE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10980073966\n",
      "{'sim_options': {'user_based': False, 'name': 'pearson_baseline'}, 'bsl_options': {'learning_rate': 0.001, 'method': 'als'}}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_bsl.best_score['RMSE'])\n",
    "print(grid_search_bsl.best_params['RMSE'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the smallest mean RMSE of 1.10980073966 over three folds of the rating_data, the model with the highest performance seems to be KNNBaseline, with parameters displayed above. We are now ready to train the model on the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "anime_algo = KNNBaseline(sim_options=sim_options1, bsl_options=bsl_options1)\n",
    "rating_trainset = rating_data.build_full_trainset()\n",
    "testing_model = anime_algo.train(rating_trainset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally define functions to help display the results of our KNNBaseline model. Note that recommend_me function will only input exact names of anime as seen on [myanimelist.net](https://myanimelist.net/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_index(x):\n",
    "    # gives index for the anime\n",
    "    return anime[anime['name']==x].index.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_me(a):\n",
    "    print('Here are 10 anime similar to', a, ':' '\\n')\n",
    "    index = get_index(a)\n",
    "    anime_nbrs = anime_algo.get_neighbors(index, k=10)\n",
    "    \n",
    "    for i in anime_nbrs[:]:\n",
    "            print(anime.iloc[i]['name'], \n",
    "                  '\\n' 'Genre: ', anime.iloc[i]['genre'],\n",
    "                  '\\n' 'Episode count: ', anime.iloc[i]['episodes'],\n",
    "                  '\\n' 'Rating out of 10:', anime.iloc[i]['rating'], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are 10 anime similar to Death Note :\n",
      "\n",
      "Kimi ni Todoke 2nd Season \n",
      "Genre:  Romance, School, Shoujo, Slice of Life \n",
      "Episode count:  12 \n",
      "Rating out of 10: 8.17 \n",
      "\n",
      "Tales of Zestiria the X: Saiyaku no Jidai \n",
      "Genre:  Action, Fantasy \n",
      "Episode count:  1 \n",
      "Rating out of 10: 7.44 \n",
      "\n",
      "3 Choume no Tama: Onegai! Momo-chan wo Sagashite!! \n",
      "Genre:  Adventure, Kids \n",
      "Episode count:  1 \n",
      "Rating out of 10: 6.24 \n",
      "\n",
      "Byousoku 5 Centimeter \n",
      "Genre:  Drama, Romance, Slice of Life \n",
      "Episode count:  3 \n",
      "Rating out of 10: 8.1 \n",
      "\n",
      "Mirai Shounen Conan: Tokubetsu-hen - Kyodaiki Gigant no Fukkatsu \n",
      "Genre:  Adventure, Drama, Sci-Fi \n",
      "Episode count:  1 \n",
      "Rating out of 10: 6.93 \n",
      "\n",
      "Chihayafuru 2 \n",
      "Genre:  Drama, Game, Josei, Slice of Life, Sports \n",
      "Episode count:  25 \n",
      "Rating out of 10: 8.52 \n",
      "\n",
      "Gakkatsu! 2nd Season \n",
      "Genre:  Comedy, School \n",
      "Episode count:  25 \n",
      "Rating out of 10: 6.51 \n",
      "\n",
      "Utawarerumono \n",
      "Genre:  Action, Drama, Fantasy, Sci-Fi \n",
      "Episode count:  26 \n",
      "Rating out of 10: 7.78 \n",
      "\n",
      "Trinity Seven OVA \n",
      "Genre:  Action, Comedy, Ecchi, Fantasy, Harem, Magic, Romance, School, Supernatural \n",
      "Episode count:  1 \n",
      "Rating out of 10: 7.53 \n",
      "\n",
      "Pokemon XY: Mega Evolution \n",
      "Genre:  Action, Adventure, Comedy, Fantasy, Kids \n",
      "Episode count:  4 \n",
      "Rating out of 10: 7.7 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "recommend_me('Death Note')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Failure\n",
    "\n",
    "These anime aren't at all like Death Note. In fact, these results are worse that part 1 :( \n",
    "\n",
    "This was my first run with the surprise package. I will have to come back to this problem to find a better approach to collab filtering - with or without using surprise. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
